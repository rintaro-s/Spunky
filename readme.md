# Spunky（LALv1biz2） アーキテクチャ仕様
# なお、制作中のためまだ動作しません

---

## 1. Spunky 全体像

Spunky は **「思考(think)」と「対話(chat)」の二重モジュール構成**を採用した、人間らしい知的エージェント。
目的は以下：

* 人間のように「考え」「評価し」「理由づけ」を行えること
* キャラクターとして自然な「会話」を返せること
* 巨大モデルに依存せず、**軽量・拡張可能・少量学習**で成立すること

### 主な構成

1. **Spunky-think**（推論・自己分析）
2. **Spunky-chat**（自然対話・出力制御）
3. **Knowledge Layer**（外部知識参照）
4. **管理・適応モジュール**（状態管理、フィードバック学習）

全体フローは：
**入力 → 理解 → 管理 → 推論(think) & 知識参照 → 応答生成(chat) → 出力**

---

## 2. Spunky-think（思考モジュール）

### 2.1 役割

* 問題に対して「人間のような思考プロセス」を再現
* 試行錯誤を行い、複数案を比較検討
* 根拠を伴う答えと「自分流のアプローチ」を作る

### 2.2 詳細プロセス（層構造）

1. **試行層 (Trial Layer)**

   * 入力問題をもとに、複数の解決案を生成
   * 生成方法：ルール展開、例示探索、知識照合
   * 出力形式：候補リスト（例：解法A, 解法B, 解法C）
   * 特徴：必ず2案以上を出す → 思考の幅を確保

2. **評価層 (Evaluation Layer)**

   * 各候補案をスコアリング（正確さ、効率、妥当性）
   * メトリクス例：

     * 正確性（数学なら数式の矛盾有無）
     * 実用性（現実問題で使えるか）
     * シンプルさ（人に説明しやすいか）
   * 手法：数値シミュレーション、ルール検証、サンプルケース適用
   * 出力形式：スコア付き候補表

3. **理由分析層 (Reason Analysis Layer)**

   * 各候補について「良い理由・悪い理由」を文章化
   * 検討失敗も残す（失敗こそ学習材料）
   * 例：

     * 成功理由：定義と一致する
     * 失敗理由：境界条件で矛盾が出る

4. **アプローチ形成層 (Approach Formation Layer)**

   * 過去の試行・理由分析を蓄積し、再利用可能な「方法論」を生成
   * 形式：メタルールや「自分流の戦略」
   * 例：

     * 「まずケースを分けて考える」
     * 「証明問題では反例を先に探す」

5. **最終決定層 (Finalization Layer)**

   * 評価＋理由＋アプローチから最良案を選択
   * Chatに渡すときは：

     1. 最終解答
     2. 理由説明
     3. 参考になりそうな別案
     4. 汎用アプローチ

---

## 3. Spunky-chat（対話モジュール）

### 3.1 役割

* ユーザーとの自然対話を担当
* Thinkの出力を「会話文」に整形
* キャラクター性（妹口調など）を維持

### 3.2 内部構成

1. **入力理解モジュール (Lightweight NLU)**

   * Intent（目的）と Entity（対象）を抽出
   * 実装例：正規表現＋小型分類器（SVM, Decision Tree）
   * Embeddingで類似度検索（例：Mini Sentence-BERT）
   * 追加：キャラクター辞書を組み込み → 感情検知

2. **会話管理モジュール (Stateful Dialog Manager)**

   * 状態遷移を制御（Finite State Machine）
   * 例：挨拶 → 雑談 → 感情対応 → 問題解決
   * 会話履歴は Key-Value ストアに保存
   * 長期記憶：古い情報は忘却曲線的に削除

3. **応答生成モジュール (Hybrid NLG)**

   * 基盤：テンプレートベース（妹口調の定型文）
   * 補強：小型 Transformer / RNN によるバリエーション付け
   * 感情制御：NLUから得た「悲しい/楽しい/怒り」を反映
   * 出力：一貫したキャラクター＋柔軟な応答

4. **フィードバック&適応モジュール (Self-Improvement Loop)**

   * 会話後に「自然さスコア」を算出（長さ、感情一致度、応答速度）
   * 改善：ルール微調整、感情分類器の閾値更新
   * 学習：オンライン少量更新（例：簡易 Q-Learning）

---

## 4. Knowledge Layer（知識参照層）

### 4.1 ソース

* Wikipedia / Fandom Wiki / 技術系まとめサイト
* 専門分野ごとのローカル知識DB

### 4.2 処理

1. クエリ解析（質問の意図を抽出）
2. 検索（全文検索＋Embedding類似度）
3. 抽出要約（重要箇所だけ残す）
4. Thinkで妥当性検証
5. Chatに渡して自然文に整形

---

## 5. 全体フロー例

### ケース1：雑談

* Chat内 NLU → FSM管理 → Hybrid NLG

### ケース2：知識質問

* Chat → Knowledge Layer → Thinkで妥当性確認 → Chat整形

### ケース3：推論（数学・論理）

* Chat → Think（試行→評価→理由→アプローチ→決定）
* Think → Chat（理由付き応答）
* Chat → ユーザー（妹口調で説明）

---

## 6. 特徴まとめ

* **人間的思考**：複数案を試す、理由を明示する
* **軽量実装**：巨大モデル依存なし、数十万パラメータ規模
* **キャラクター一貫性**：FSMとテンプレート制御で崩れない
* **知識＋推論融合**：Wiki参照と内部推論の両立
* **自己改善**：フィードバックループで会話自然度を強化

---

## 7. 技術スタック候補

* NLU：transformersライブラリによる言語モデル（RoBERTa等）のファインチューニング
* FSM：自作ルール or Rasa-like構造
* DB：SQLite / Redis (短期記憶)
* NLG：テンプレート＋小型RNN/Transformer
* 評価：ルールベース＋数値検証モジュール
* 学習：オフライン少量サンプル（数百件）＋オンライン更新

---

## 8. 開発フェーズ案

1. **最小構成試作**

   * Chat：FSM＋テンプレート応答
   * Think：試行→評価まで
2. **知識参照追加**

   * Wikipedia要約モジュール連携
3. **理由分析＋アプローチ形成**

   * 内部に「説明」を生成
4. **自己改善ループ導入**

   * 会話後にスコアリング

---

# まとめ

この仕様で Spunky は：

* **Chat が「表の顔」**（妹キャラで会話）
* **Think が「裏の頭脳」**（推論・検証・理由分析）
* **Knowledge が「参考書」**（事実ベースの補強）
* **管理/適応が「記憶と成長」**（会話を続けるほど賢く自然に）

---
